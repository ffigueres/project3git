---
title: "Data Science Skills"
author: "Jim Ng, Lewris Mota, Suma Gopal, Fernando Figueres"
date: "March 22, 2019"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(kableExtra)
library(plyr)
library(Hmisc)
library(sqldf)
#library(RMySQL)
```
***
###Data Acquisition { .tabset}

#### Data loading

In this stage, the original dataframe will be loaded into the environment in order to start the cleaning process.

```{r, echo = FALSE}
indeed_dt <- read.csv("indeed_job_dataset.csv", stringsAsFactors = F)
# clean up header
names(indeed_dt) <- tolower(names(indeed_dt))

```

####  Original Dataset Display

Dimensions:
```{r, echo = FALSE}
dim(indeed_dt)

```


Display of the first 50 rows from the data.
```{r, echo=FALSE}
indeed_dt %>%
  head(.,n=50) %>% 
  kable() %>%
  kable_styling()%>%
  scroll_box(width = "100%",height = "300px")
```


### Transformations

```{r, warning=FALSE, echo = FALSE}

indeed_dt <- indeed_dt %>%
              mutate(jk_id = str_extract_all(link, pattern = "jk=[[:alnum:]]+&") %>% 
                              str_replace_all(., pattern = "jk=|&", replacement = ""),
                      fcc_id = str_extract_all(link, pattern = "fccid=[[:alnum:]]+&") %>% 
                              str_replace_all(., pattern = "fccid=|&", replacement = ""))

```

```{r, echo = FALSE}


#indeed_dt %>% head()
sapply(list(indeed_dt$jk_id, indeed_dt$fcc_id), function(x){length(unique(x))})


```


```{r, echo = FALSE}
# lookup both Ids, some links are missing the "jk_id"
jk_id.lookup <- plyr::count(indeed_dt, "jk_id") %>% arrange(desc(freq))
table(jk_id.lookup$freq); 
#head(jk_id.lookup)

```

```{r, echo = FALSE}
# "fcc_id" can be duplicated because the same company can post the same job position with different attributes, most likely offering the same position in different locations
fcc_id.lookup <- count(indeed_dt, "fcc_id") %>% arrange(desc(freq))
#head(fcc_id.lookup)

```

```{r, echo = FALSE}
# the result indicates that each "jk_id" is unique in the data set; there is no duplication for any "jk_id"
# however, 99 jobs have missing "jk_id"
# why? what are these 99 jobs? 

jk_id.missing <- indeed_dt %>%
        filter(jk_id == "character(0)") 

```

```{r, echo = FALSE}
# let's fix these "jk_id" - these are written differently as there's no "jk=" in these links        
# e.g. https://www.indeed.com/company/Wag!/jobs/Data-Engineer-0633d6309b9f2be8?fccid=381733c3e1596619&vjs=3
jk_id.missing <- jk_id.missing %>%
        dplyr::mutate(jk_id = str_extract_all(jk_id.missing$link, pattern = "-[[:alnum:]]+\\?fccid") %>%
                              str_replace_all(., pattern = "-|\\?fccid", replacement = ""))



```

```{r, echo = FALSE}
# let's 'union all' both sets
indeed_dt <- indeed_dt %>%
        dplyr::filter(x %nin% jk_id.missing$x) %>%
        dplyr::bind_rows(., jk_id.missing)

```
***
### Data Normalization

we are going to create a simple star schema for this data set we need four tables, i.e. "job_post_specific", "job_position", "company", & "description". "job_post_specific" table - "jk_id" is the primary key. Each "jk_id" is unique and that represents a post for one job position from a company.

"job_position" table - beware of the original "fcc_id"! Note, the "job_post_specific" and "job_position" tables are different. The same job position is supposed to share an idential and unique "fcc_id"; however, there can be multiple posting. In other words, we expect to see the same "fcc_id" for multiple "jk_id". For instance, Google posted four identical position "Google AI Resident, 2019 Start (Fixed-Term Employee)" with the same "fcc_id" (a5b4499d9e91a5c6) but four different "jk_id". These four positions were offered in different locations (NY, MA, CA, & WA)

We should consider these four positions as one when counting for skill sets; otherwise, we will inflate our numbers when calculating for the percentage based on skill sets; however, the data is also messy in terms of some companies posted different job positions with the same "fcc_id"! Using Google and the same "fcc_id" (a5b4499d9e91a5c6) as an example, there are actually 40 entries in the data set that share the same "fcc_id"! That simply means that there are different job positions share the same "fcc_id", but we also have identical jobs share the same "fcc_id" with different entries in the data set because they can be offered in different locations
one extreme case, Booz Allen Hamilton posted 151 different jobs with identical "fcc_id" (4e041af1d0af1bc8)! We must clean up the messy "fcc_id" before splitting up the data set into four tables:

We must 1) remove duplication of identical jobs (job_title, queried_salary, job_type, skill, company), and 2) create unique "fcc_unique_id" as the primary key. Last but not least, we also need to clean up the "company" table by creating a company Id and performing simple Change-Data-Capture

#### Job Position Dataframe
```{r, echo = FALSE}
job_position <- indeed_dt %>%
        dplyr::select(fcc_id, job_title, queried_salary, job_type, skill, company) %>%
        dplyr::distinct() %>%
        # create a "fcc_unique_id" after the dplyr::distinct()
        dplyr::mutate(fcc_unique_id = paste(row_number(), fcc_id, sep = "_"))
```

#### Job Post Specific
```{r, echo = FALSE}
job_post_specific <- sqldf("
select df.jk_id
, jp.fcc_unique_id
, df.link
, df.date_since_posted
, df.location 
from job_position jp
join (
        select jk_id, fcc_id, job_title, queried_salary, job_type, skill, company
        , link, date_since_posted, location
        from indeed_dt
) df on jp.fcc_id = df.fcc_id
and jp.job_title = df.job_title 
and jp.queried_salary = df.queried_salary 
and jp.job_type = df.job_type 
and jp.skill = df.skill 
and jp.company = df.company
")
```

```{r message = FALSE, echo = FALSE}
#########################
# clean-up job_position #
#########################
# create a company ID
company_index <- indeed_dt %>%
        dplyr::select(company) %>%
        distinct() %>% 
        arrange(company) %>%
        dplyr::mutate(company_id = paste("c", row_number(), sep = "_"))

job_position <- job_position %>%
        dplyr::left_join(., company_index) %>%
        dplyr::select(fcc_unique_id, job_title, queried_salary, job_type, skill, company_id)
DT::datatable(job_post_specific %>% 
group_by(location) %>% tally())


```
```{r message = FALSE, echo = FALSE}
###########
# company #
###########
company <- indeed_dt %>%
        dplyr::select(company, no_of_reviews, no_of_stars, company_revenue, company_employees, company_industry) %>%
        distinct() %>%
        dplyr::left_join(., company_index) %>%
        dplyr::select(company_id, everything()) %>%
        arrange(company_id)

# perform simple CDC - Chang-Data-Capture
# get rid of multiple entries by returning the max of "no_of_stars" and "no_of_reviews" b/c we suppose that's the latest update for the company
company <- sqldf("
select company_id, company, company_revenue, company_employees, company_industry
, max(no_of_stars) as no_of_stars
, max(no_of_reviews) as no_of_reviews
from company
group by 1, 2, 3, 4, 5
order by company
"
)    
```
####  Description
```{r, echo = FALSE}

description <- indeed_dt %>%
        select(link, description) %>%
        distinct()
```
***

#### Job Postion
```{r echo=FALSE}

job_position %>%
  head() %>% 
  kable() %>%
  kable_styling()%>%
  scroll_box(width = "100%",height = "300px")

```


#### Job Post
```{r echo=FALSE}
job_post_specific %>%
  head() %>% 
  kable() %>%
  kable_styling()%>%
  scroll_box(width = "100%",height = "300px")

```

#### Company
```{r echo=FALSE}
company %>%
  head() %>% 
  kable() %>%
  kable_styling()%>%
  scroll_box(width = "100%",height = "300px")
```


#### Description
```{r echo=FALSE}
description %>%
  head() %>% 
  kable() %>%
  kable_styling()%>%
  scroll_box(width = "100%",height = "300px")
```


### Database Storage

```{r eval = FALSE, echo = FALSE, echo = FALSE}
# #Use this connection first, if a db hasn't been created.
# mdb <- DBI::dbConnect(
#   RMySQL::MySQL(),
#   host = "35.226.125.86",
#   user = "root",
#   password = "rootpass"#rstudioapi::askForPassword("Database password"))
#   
# # Create the db
# dbSendQuery(mdb, 'CREATE SCHEMA `project3`')
#   
# #Connection with schema specified
#  mdb2 <- DBI::dbConnect(
#   RMySQL::MySQL(),
#   dbname = 'project3',
#   host = "35.226.125.86",
#   user = "root",
#   password = rstudioapi::askForPassword("Database password")
#     
# # Create db tables and write data frame contents
# dbWriteTable(mdb2, 'company', company, row.names = FALSE)
# dbWriteTable(mdb2, 'job_postion', job_position, row.names = FALSE)
# dbWriteTable(mdb2, 'job_post_specific', job_post_specific, row.names = FALSE)
# dbWriteTable(mdb2, 'description', description, row.names = FALSE)
```

### Analysis

```{r, warning=FALSE, echo = FALSE}
skills <-  job_position$skill  %>% str_extract_all("(?<=\\')([a-zA-Z]{1,}).*?(?=\\')")

positionFinal <- data.frame(company_id = rep(job_position$company_id,sapply(skills,length)),
                            skills=unlist(skills))

positionFinal <- left_join(positionFinal,company,by="company_id")


#positionFinal <- positionFinal %>% filter(.$company_industry != "")
```


```{r Import and Wide, echo = FALSE}
dfwide <- job_position %>% 
  select(fcc_unique_id, skill) %>% #Take the link as an identifier and the skills column
  mutate(skill = stringi::stri_extract_all(skill,regex = "(?!')((?:''|[^'])*)(?=(',)|(']))"), V2 = 1) %>% #extract individual skills
  unnest(skill, .id = "id") %>% #Skills to rows
  spread(skill, V2, fill = 0) %>%  #Skills rows to columns
  select (-c(`<NA>`,id)) %>% #remove unused columns
  dplyr::rename(NLP = `Natural Language Processing`) #Makes the chart look better
```

```{r Tall, echo = FALSE}
dftall <- dfwide %>% 
  gather(key = "skill",value = "required", 2:465)
```

```{r Summarise, echo = FALSE, message = FALSE}
dftop <- dftall %>% 
  group_by(skill) %>% 
  dplyr::summarise(count = sum(required)) %>% 
  arrange(count) %>% 
  top_n(30)
```

The chart below tallies the the skill count accross the entire data set. We see that Python is the language of choice followed by R and Java. For database related technologies, SQL is the clear choice due to it's ubiquity followed by "big data" variants such as Hadoop and Spark.

```{r fig.width=4, fig.height=6, echo = FALSE}
p<-ggplot(data=dftop, aes(x=reorder(skill,count), y=count), width=.5,position = position_dodge(width = 60)) +
  ggtitle("Data Science Skills")+
  geom_bar(stat="identity", fill="steelblue")+
  theme_minimal() +
  coord_flip() 
p
```


## Salary Index

As part of our analsys, we've calculated the relative value of each skill by dividing the expected salary of each position by the number of required skills. With this measure, we hoped to determine if some data scietist roles required less populat skills which command a higher salary.

Epected salary intervals were converted to a 1 to 6 scale with 6 corresponding to expected salries >$160000. This number was divided by the total number of skills and that weight is assigned to the skill. We later aggregated the mean and sums of this values as show in the charts below.

Our first chart plots the sum of the relative values and gives us a very similar result to the raw count scores from the above chart.

The next chart calculates the avegrage of relative values in this shows a very different picture. Less commong skills which are associated with higher paying jobs rise to the top. This chart is heavily influenced my skills with a low job count so the results need to be intepreted with caution. Rather than using it infer general trends, a candiate might find it useful to see if a skill he or she has might  opne the door to a specialized role.

```{r Import and Wide Salary, echo = FALSE}
dfsalary<- indeed_dt %>% 
  select(link,no_of_skills, queried_salary, skill) %>% #Take the link as an identifier and the skills column
  mutate(skill = stringi::stri_extract_all(skill,regex = "(?!')((?:''|[^'])*)(?=(',)|(']))"), V2 = 1) %>% #extract individual skills
  unnest(skill, .id = "id") %>% #Skills to rows
  spread(skill, V2, fill = 0) %>%  #Skills rows to columns
  select (-c(`<NA>`,id)) %>% #remove unused columns
  dplyr::rename(NLP = `Natural Language Processing`) %>%  #Makes the chart look better
  gather(key = "skill",value = "required", 4:467) %>% 
  filter(required == 1) %>% 
  mutate(salindex = queried_salary) %>% 
  mutate(salindex = str_replace(salindex, "<80000", "1")) %>%
  mutate(salindex = str_replace(salindex, "80000-99999", "2")) %>% 
  mutate(salindex = str_replace(salindex, "100000-119999", "3")) %>% 
  mutate(salindex = str_replace(salindex, "120000-139999", "4")) %>% 
  mutate(salindex = str_replace(salindex, "140000-159999", "5")) %>% 
  mutate(salindex = str_replace(salindex, ">160000", "6")) %>% 
  mutate(skillval = as.numeric(salindex)/no_of_skills)
```

```{r Summarise sum val,include = FALSE}
dftopsals <- dfsalary %>% 
  group_by(skill) %>% 
  dplyr::summarise(valsum = sum(skillval)) %>% 
  arrange(valsum) %>% 
  top_n(30)
```


```{r fig.width=4, fig.height=6, echo = FALSE}
p<-ggplot(data=dftopsals, aes(x=reorder(skill,valsum), y=valsum), width=.5,position = position_dodge(width = 60)) +
  ggtitle("Sum of Relative Skill Value")+
  geom_bar(stat="identity", fill="steelblue")+
  theme_minimal() +
  coord_flip() 
p
```



```{r Summarise mean val,include = FALSE}
dftopsalm <- dfsalary %>% 
  group_by(skill) %>% 
  dplyr::summarise(valmean = mean(skillval)) %>% 
  arrange(valmean) %>% 
  top_n(30)
```

```{r fig.width=5, fig.height=6, echo = FALSE}
p<-ggplot(data=dftopsalm, aes(x=reorder(skill,valmean), y=valmean), width=.5,position = position_dodge(width = 60)) +
  ggtitle("Average of Relative Skill Value")+
  geom_bar(stat="identity", fill="steelblue")+
  theme_minimal() +
  coord_flip() 
p
```




## Location 

```{r Import and Wide Location, echo = FALSE}
dflocation <- indeed_dt %>% 
  select(location, skill) %>% #Take the link as an identifier and the skills column
  mutate(skill = stringi::stri_extract_all(skill,regex = "(?!')((?:''|[^'])*)(?=(',)|(']))"), V2 = 1) %>% #extract individual skills
  unnest(skill, .id = "id") %>% #Skills to rows
  spread(skill, V2, fill = 0) %>%  #Skills rows to columns
  select (-c(`<NA>`,id)) %>% #remove unused columns
  dplyr::rename(NLP = `Natural Language Processing`) %>%  #Makes the chart look better
  gather(key = "skill",value = "required", 2:465) %>% 
  filter(required == 1) %>% 
  filter(location != "") %>% 
  group_by(location, skill) %>% 
  dplyr::summarise(count = sum(required)) %>% 
  arrange(location)
```

```{r fig.width=6, fig.height=6, echo = FALSE}
ggplot(data = dflocation, aes(x=skill, y=location, fill=count)) + 
  geom_tile()
```

