---
title: "Data Science Skills"
author: "Jim Ng, Lewris Mota, Suma Gopal, Fernando Figueres"
date: "March 22, 2019"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(kableExtra)
library(plyr)
library(Hmisc)
library(sqldf)
#library(RMySQL)
```
***
###Data Acquisition { .tabset}

#### Data loading

In this stage, the original dataframe will be loaded into the environment in order to start the cleaning process.

```{r}
indeed_dt <- read.csv("indeed_job_dataset.csv", stringsAsFactors = F)
# clean up header
names(indeed_dt) <- tolower(names(indeed_dt))

```

####  Original Dataset Display

Dimensions:
```{r}
dim(indeed_dt)

```


Display of the first 50 rows from the data.
```{r, echo=FALSE}
indeed_dt %>%
  head(.,n=50) %>% 
  kable() %>%
  kable_styling()%>%
  scroll_box(width = "100%",height = "300px")
```


### Transformations

```{r, warning=FALSE}

indeed_dt <- indeed_dt %>%
              mutate(jk_id = str_extract_all(link, pattern = "jk=[[:alnum:]]+&") %>% 
                              str_replace_all(., pattern = "jk=|&", replacement = ""),
                      fcc_id = str_extract_all(link, pattern = "fccid=[[:alnum:]]+&") %>% 
                              str_replace_all(., pattern = "fccid=|&", replacement = ""))

```

```{r}


#indeed_dt %>% head()
sapply(list(indeed_dt$jk_id, indeed_dt$fcc_id), function(x){length(unique(x))})


```


```{r}
# lookup both Ids, some links are missing the "jk_id"
jk_id.lookup <- plyr::count(indeed_dt, "jk_id") %>% arrange(desc(freq))
table(jk_id.lookup$freq); 
#head(jk_id.lookup)

```

```{r}
# "fcc_id" can be duplicated because the same company can post the same job position with different attributes, most likely offering the same position in different locations
fcc_id.lookup <- count(indeed_dt, "fcc_id") %>% arrange(desc(freq))
#head(fcc_id.lookup)

```

```{r}
# the result indicates that each "jk_id" is unique in the data set; there is no duplication for any "jk_id"
# however, 99 jobs have missing "jk_id"
# why? what are these 99 jobs? 

jk_id.missing <- indeed_dt %>%
        filter(jk_id == "character(0)") 

```

```{r}
# let's fix these "jk_id" - these are written differently as there's no "jk=" in these links        
# e.g. https://www.indeed.com/company/Wag!/jobs/Data-Engineer-0633d6309b9f2be8?fccid=381733c3e1596619&vjs=3
jk_id.missing <- jk_id.missing %>%
        dplyr::mutate(jk_id = str_extract_all(jk_id.missing$link, pattern = "-[[:alnum:]]+\\?fccid") %>%
                              str_replace_all(., pattern = "-|\\?fccid", replacement = ""))



```

```{r}
# let's 'union all' both sets
indeed_dt <- indeed_dt %>%
        dplyr::filter(x %nin% jk_id.missing$x) %>%
        dplyr::bind_rows(., jk_id.missing)

```
***
### Data Normalization

we are going to create a simple star schema for this data set we need four tables, i.e. "job_post_specific", "job_position", "company", & "description". "job_post_specific" table - "jk_id" is the primary key. Each "jk_id" is unique and that represents a post for one job position from a company.

"job_position" table - beware of the original "fcc_id"! Note, the "job_post_specific" and "job_position" tables are different. The same job position is supposed to share an idential and unique "fcc_id"; however, there can be multiple posting. In other words, we expect to see the same "fcc_id" for multiple "jk_id". For instance, Google posted four identical position "Google AI Resident, 2019 Start (Fixed-Term Employee)" with the same "fcc_id" (a5b4499d9e91a5c6) but four different "jk_id". These four positions were offered in different locations (NY, MA, CA, & WA)

We should consider these four positions as one when counting for skill sets; otherwise, we will inflate our numbers when calculating for the percentage based on skill sets; however, the data is also messy in terms of some companies posted different job positions with the same "fcc_id"! Using Google and the same "fcc_id" (a5b4499d9e91a5c6) as an example, there are actually 40 entries in the data set that share the same "fcc_id"! That simply means that there are different job positions share the same "fcc_id", but we also have identical jobs share the same "fcc_id" with different entries in the data set because they can be offered in different locations
one extreme case, Booz Allen Hamilton posted 151 different jobs with identical "fcc_id" (4e041af1d0af1bc8)! We must clean up the messy "fcc_id" before splitting up the data set into four tables:

We must 1) remove duplication of identical jobs (job_title, queried_salary, job_type, skill, company), and 2) create unique "fcc_unique_id" as the primary key. Last but not least, we also need to clean up the "company" table by creating a company Id and performing simple Change-Data-Capture

#### Job Position Dataframe
```{r}
job_position <- indeed_dt %>%
        dplyr::select(fcc_id, job_title, queried_salary, job_type, skill, company) %>%
        dplyr::distinct() %>%
        # create a "fcc_unique_id" after the dplyr::distinct()
        dplyr::mutate(fcc_unique_id = paste(row_number(), fcc_id, sep = "_"))



```

#### Job Post Specific
```{r}
job_post_specific <- sqldf("
select df.jk_id
, jp.fcc_unique_id
, df.link
, df.date_since_posted
, df.location 
from job_position jp
join (
        select jk_id, fcc_id, job_title, queried_salary, job_type, skill, company
        , link, date_since_posted, location
        from indeed_dt
) df on jp.fcc_id = df.fcc_id
and jp.job_title = df.job_title 
and jp.queried_salary = df.queried_salary 
and jp.job_type = df.job_type 
and jp.skill = df.skill 
and jp.company = df.company
")
```

```{r}
#########################
# clean-up job_position #
#########################
# create a company ID
company_index <- indeed_dt %>%
        dplyr::select(company) %>%
        distinct() %>% 
        arrange(company) %>%
        dplyr::mutate(company_id = paste("c", row_number(), sep = "_"))

job_position <- job_position %>%
        dplyr::left_join(., company_index) %>%
        dplyr::select(fcc_unique_id, job_title, queried_salary, job_type, skill, company_id)


```
```{r}
###########
# company #
###########
company <- indeed_dt %>%
        dplyr::select(company, no_of_reviews, no_of_stars, company_revenue, company_employees, company_industry) %>%
        distinct() %>%
        dplyr::left_join(., company_index) %>%
        dplyr::select(company_id, everything()) %>%
        arrange(company_id)

# perform simple CDC - Chang-Data-Capture
# get rid of multiple entries by returning the max of "no_of_stars" and "no_of_reviews" b/c we suppose that's the latest update for the company
company <- sqldf("
select company_id, company, company_revenue, company_employees, company_industry
, max(no_of_stars) as no_of_stars
, max(no_of_reviews) as no_of_reviews
from company
group by 1, 2, 3, 4, 5
order by company
"
)    
```
####  Description
```{r}

description <- indeed_dt %>%
        select(link, description) %>%
        distinct()
```
***

#### Job Postion
```{r echo=FALSE}

job_position %>%
  head() %>% 
  kable() %>%
  kable_styling()%>%
  scroll_box(width = "100%",height = "300px")

```


#### Job Post
```{r echo=FALSE}
job_post_specific %>%
  head() %>% 
  kable() %>%
  kable_styling()%>%
  scroll_box(width = "100%",height = "300px")

```

#### Company
```{r echo=FALSE}
company %>%
  head() %>% 
  kable() %>%
  kable_styling()%>%
  scroll_box(width = "100%",height = "300px")
```


#### Description
```{r echo=FALSE}
description %>%
  head() %>% 
  kable() %>%
  kable_styling()%>%
  scroll_box(width = "100%",height = "300px")
```


### Database Storage

```{r eval = FALSE, echo = FALSE, ff}
# #Use this connection first, if a db hasn't been created.
# mdb <- DBI::dbConnect(
#   RMySQL::MySQL(),
#   host = "35.226.125.86",
#   user = "root",
#   password = "rootpass"#rstudioapi::askForPassword("Database password"))
#   
# # Create the db
# dbSendQuery(mdb, 'CREATE SCHEMA `project3`')
#   
# #Connection with schema specified
#  mdb2 <- DBI::dbConnect(
#   RMySQL::MySQL(),
#   dbname = 'project3',
#   host = "35.226.125.86",
#   user = "root",
#   password = rstudioapi::askForPassword("Database password")
#     
# # Create db tables and write data frame contents
# dbWriteTable(mdb2, 'company', company, row.names = FALSE)
# dbWriteTable(mdb2, 'job_postion', job_position, row.names = FALSE)
# dbWriteTable(mdb2, 'job_post_specific', job_post_specific, row.names = FALSE)
# dbWriteTable(mdb2, 'description', description, row.names = FALSE)
```

### Analysis

```{r, warning=FALSE}
skills <-  job_position$skill  %>% str_extract_all("(?<=\\')([a-zA-Z]{1,}).*?(?=\\')")

positionFinal <- data.frame(company_id = rep(job_position$company_id,sapply(skills,length)),
                            skills=unlist(skills))

positionFinal <- left_join(positionFinal,company,by="company_id")


#positionFinal <- positionFinal %>% filter(.$company_industry != "")
```


```{r Import and Wide}
dfwide <- job_position %>% 
  select(fcc_unique_id, skill) %>% #Take the link as an identifier and the skills column
  mutate(skill = stringi::stri_extract_all(skill,regex = "(?!')((?:''|[^'])*)(?=(',)|(']))"), V2 = 1) %>% #extract individual skills
  unnest(skill, .id = "id") %>% #Skills to rows
  spread(skill, V2, fill = 0) %>%  #Skills rows to columns
  select (-c(`<NA>`,id)) %>% #remove unused columns
  dplyr::rename(NLP = `Natural Language Processing`) #Makes the chart look better
```

```{r Tall}
dftall <- dfwide %>% 
  gather(key = "skill",value = "required", 2:465)
```

```{r Summarise}
dftop <- dftall %>% 
  group_by(skill) %>% 
  dplyr::summarise(count = sum(required)) %>% 
  arrange(count) %>% 
  top_n(30)
```

```{r fig.width=4, fig.height=6}
p<-ggplot(data=dftop, aes(x=reorder(skill,count), y=count), width=.5,position = position_dodge(width = 60)) +
  ggtitle("Data Science Skills")+
  geom_bar(stat="identity", fill="steelblue")+
  theme_minimal() +
  coord_flip() 
p
```


## Salary Index



```{r Import and Wide}
dfsalary<- indeed_dt %>% 
  select(link,no_of_skills, queried_salary, skill) %>% #Take the link as an identifier and the skills column
  mutate(skill = stringi::stri_extract_all(skill,regex = "(?!')((?:''|[^'])*)(?=(',)|(']))"), V2 = 1) %>% #extract individual skills
  unnest(skill, .id = "id") %>% #Skills to rows
  spread(skill, V2, fill = 0) %>%  #Skills rows to columns
  select (-c(`<NA>`,id)) %>% #remove unused columns
  dplyr::rename(NLP = `Natural Language Processing`) %>%  #Makes the chart look better
  gather(key = "skill",value = "required", 4:467) %>% 
  filter(required == 1) %>% 
  mutate(salindex = queried_salary) %>% 
  mutate(salindex = str_replace(salindex, "<80000", "1")) %>%
  mutate(salindex = str_replace(salindex, "80000-99999", "2")) %>% 
  mutate(salindex = str_replace(salindex, "100000-119999", "3")) %>% 
  mutate(salindex = str_replace(salindex, "120000-139999", "4")) %>% 
  mutate(salindex = str_replace(salindex, "140000-159999", "5")) %>% 
  mutate(salindex = str_replace(salindex, ">160000", "6")) %>% 
  mutate(skillval = as.numeric(salindex)/no_of_skills)
```

```{r Summarise mean val}
dftopsalm <- dfsalary %>% 
  group_by(skill) %>% 
  dplyr::summarise(valmean = mean(skillval)) %>% 
  arrange(valmean) %>% 
  top_n(30)
```

```{r fig.width=5, fig.height=6}
p<-ggplot(data=dftopsalm, aes(x=reorder(skill,valmean), y=valmean), width=.5,position = position_dodge(width = 60)) +
  ggtitle("Data Science Skills")+
  geom_bar(stat="identity", fill="steelblue")+
  theme_minimal() +
  coord_flip() 
p
```



```{r Summarise sum val}
dftopsals <- dfsalary %>% 
  group_by(skill) %>% 
  dplyr::summarise(valsum = sum(skillval)) %>% 
  arrange(valsum) %>% 
  top_n(30)
```


```{r fig.width=4, fig.height=6}
p<-ggplot(data=dftopsals, aes(x=reorder(skill,valsum), y=valsum), width=.5,position = position_dodge(width = 60)) +
  ggtitle("Data Science Skills")+
  geom_bar(stat="identity", fill="steelblue")+
  theme_minimal() +
  coord_flip() 
p
```


## Location 




```{r Import and Wide}
dflocation <- indeed_dt %>% 
  select(location, skill) %>% #Take the link as an identifier and the skills column
  mutate(skill = stringi::stri_extract_all(skill,regex = "(?!')((?:''|[^'])*)(?=(',)|(']))"), V2 = 1) %>% #extract individual skills
  unnest(skill, .id = "id") %>% #Skills to rows
  spread(skill, V2, fill = 0) %>%  #Skills rows to columns
  select (-c(`<NA>`,id)) %>% #remove unused columns
  dplyr::rename(NLP = `Natural Language Processing`) %>%  #Makes the chart look better
  gather(key = "skill",value = "required", 2:465) %>% 
  filter(required == 1) %>% 
  filter(location != "") %>% 
  group_by(location, skill) %>% 
  dplyr::summarise(count = sum(required)) %>% 
  arrange(location)
```

```{r}
(p <- ggplot(dflocation, aes(skill, location)) + geom_tile(aes(fill = dflocation$c),
+     colour = "white") + scale_fill_gradient(low = "white",
+     high = "steelblue"))
```

```{r fig.width=6, fig.height=6}
ggplot(data = dflocation, aes(x=skill, y=location, fill=count)) + 
  geom_tile()
```

